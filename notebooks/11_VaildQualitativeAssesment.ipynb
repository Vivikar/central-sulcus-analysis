{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import hydra\n",
    "import pyrootutils\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "from pytorch_lightning import (Callback, LightningDataModule, LightningModule,\n",
    "                               Trainer)\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "# pyrootutils.setup_root(__file__, indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "import src.utils.default as utils\n",
    "\n",
    "log = utils.get_pylogger(__name__)\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "from src.models.simclr import SimCLR\n",
    "\n",
    "from src.models.unet3d.model_encoders import UNet3D as UNet3D_Encoder\n",
    "\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "sitk.ProcessObject_SetGlobalWarningDisplay(False)\n",
    "test_path = '/mrhome/vladyslavz/Pictures/test_imgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-11 11:23:59,786 - Len of train examples 38 len of validation examples 12\n",
      "Loading encoder weights from checkpoint...\n",
      "/mrhome/vladyslavz/git/central-sulcus-analysis/sulci_segm_logs/sst-bvisa-1x-monai-BasicUnet/runs/2023-04-10_11-38-09/checkpoints/epoch-108_val_loss-0.078.ckpt\n",
      "U-Net Embedding dimension: 458752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n",
      "Attribute 'loss_function' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_function'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_target_': 'src.data.bvisa_augm_dm.CS_DataModule', 'dataset_cfg': {'dataset': 'bvisa', 'target': 'central_sulcus', 'dataset_path': '/mrhome/vladyslavz/git/central-sulcus-analysis/data/brainvisa_augm/nobackup/generated', 'use_half_brain': False, 'resample': None, 'crop2content': False, 'padd2same_size': '256-124-256'}, 'train_batch_size': 1, 'validation_batch_size': 1, 'num_workers': 1, 'double_validation': True}\n"
     ]
    }
   ],
   "source": [
    "segm_cfg = OmegaConf.load('/mrhome/vladyslavz/git/central-sulcus-analysis/sulci_segm_logs/CS1x_tversky_BVISA_SST_monai_PRETRAINED/runs/2023-04-10_16-04-53/.hydra/config.yaml')\n",
    "CHKP = '/mrhome/vladyslavz/git/central-sulcus-analysis/sulci_segm_logs/CS1x_tversky_BVISA_SST_monai_PRETRAINED/runs/2023-04-10_16-04-53/checkpoints/epoch-146-Esubj-0.4199.ckpt'\n",
    "\n",
    "\n",
    "segm_datamodule: LightningDataModule = hydra.utils.instantiate(segm_cfg.data)\n",
    "\n",
    "segm_model: LightningModule = hydra.utils.instantiate(segm_cfg.model,\n",
    "                                                      freeze_encoder=False,\n",
    "                                                      monai=True)\n",
    "\n",
    "print(segm_cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading encoder weights from checkpoint...\n",
      "/mrhome/vladyslavz/git/central-sulcus-analysis/sulci_segm_logs/sst-bvisa-1x-monai-BasicUnet/runs/2023-04-10_11-38-09/checkpoints/epoch-108_val_loss-0.078.ckpt\n",
      "U-Net Embedding dimension: 458752\n"
     ]
    }
   ],
   "source": [
    "segm_model = segm_model.load_from_checkpoint(CHKP,\n",
    "                                             freeze_encoder=False,\n",
    "                                             monai=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "\n",
    "val_sample = segm_datamodule.val_dataset[idx]\n",
    "\n",
    "img = val_sample['image']\n",
    "target = val_sample['target']\n",
    "caseid = val_sample['caseid']\n",
    "sitk_img = sitk.ReadImage(segm_datamodule.val_dataset.img_paths[idx][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    segm_pred = segm_model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 124)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sitk_img.GetSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 124, 256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segm_pred_sitk.GetSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_pred_bin = torch.softmax(segm_pred, dim=1)[:,:1,:,:,:].squeeze(0).squeeze(0).numpy()\n",
    "\n",
    "segm_pred_sitk = sitk.GetImageFromArray(segm_pred_bin)\n",
    "target_img = sitk.GetImageFromArray(target.numpy().astype(np.uint8))\n",
    "\n",
    "# segm_pred_sitk.CopyInformation(sitk_img)\n",
    "# target_img.CopyInformation(sitk_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk_img = sitk.GetImageFromArray(img[0].numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitk.WriteImage(segm_pred_sitk, f'{test_path}/segm_pred_sitk.nii.gz')\n",
    "sitk.WriteImage(sitk_img, f'{test_path}/img.nii.gz')\n",
    "sitk.WriteImage(target_img, f'{test_path}/target.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [x for x in Path('/mrhome/vladyslavz/git/SynthSeg/data/training_label_maps').glob('**/training_seg*.nii.gz')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:03<00:00,  5.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(imgs):\n",
    "    img = sitk.ReadImage(str(i))\n",
    "    img_array = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    img_array = (img_array ==24).astype(np.int16)\n",
    "    img_array_csf = sitk.GetImageFromArray(img_array)\n",
    "    img_array_csf.CopyInformation(img)\n",
    "    \n",
    "    out = str(i).replace('training_seg', 'csf_mask')\n",
    "    sitk.WriteImage(img_array_csf, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mrhome/vladyslavz/git/central-sulcus-analysis/data/synthseg_corrected/nobackup/training_seg_20/csf_mask_99.nii.gz'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.UNet3D import  BasicUNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-Net Embedding dimension: 458752\n"
     ]
    }
   ],
   "source": [
    "simclr = SimCLR.load_from_checkpoint('/mrhome/vladyslavz/git/central-sulcus-analysis/sulci_segm_logs/sst-bvisa-1x-monai-BasicUnet/runs/2023-04-10_11-38-09/checkpoints/epoch-108_val_loss-0.078.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading encoder weights from checkpoint...\n",
      "/mrhome/vladyslavz/git/central-sulcus-analysis/sulci_segm_logs/sst-bvisa-1x-monai-BasicUnet/runs/2023-04-10_11-38-09/checkpoints/epoch-108_val_loss-0.078.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-Net Embedding dimension: 458752\n",
      "Freezing encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attribute 'net' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['net'])`.\n",
      "Attribute 'loss_function' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_function'])`.\n"
     ]
    }
   ],
   "source": [
    "unet = BasicUNet3D.load_from_checkpoint('/mrhome/vladyslavz/git/central-sulcus-analysis/sulci_segm_logs/CS1x_tversky_BVISA_SST_monai_PRETRAINED_frozenENCODER_orientCOrrect/runs/2023-04-11_10-38-38/checkpoints/epoch-280-Esubj-0.4681.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr.encoder.conv_0 = unet.net.conv_0 \n",
    "simclr.encoder.down_1 = unet.net.down_1 \n",
    "simclr.encoder.down_2 = unet.net.down_2 \n",
    "simclr.encoder.down_3 = unet.net.down_3 \n",
    "simclr.encoder.down_4 = unet.net.down_4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /mrhome/vladyslavz/anaconda3/envs/css/lib/python3.10 ...\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An invalid dataloader was passed to `Trainer.fit(train_dataloaders=...)`. Either pass the dataloader to the `.fit()` method OR implement `def train_dataloader(self):` in your LightningModule/LightningDataModule.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[39m=\u001b[39m Trainer()\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(simclr)\n",
      "File \u001b[0;32m~/anaconda3/envs/css/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    610\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/css/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/anaconda3/envs/css/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:638\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[39mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    634\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou cannot pass `train_dataloader` or `val_dataloaders` to `trainer.fit(datamodule=...)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    635\u001b[0m     )\n\u001b[1;32m    637\u001b[0m \u001b[39m# links data to the trainer\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_connector\u001b[39m.\u001b[39;49mattach_data(\n\u001b[1;32m    639\u001b[0m     model, train_dataloaders\u001b[39m=\u001b[39;49mtrain_dataloaders, val_dataloaders\u001b[39m=\u001b[39;49mval_dataloaders, datamodule\u001b[39m=\u001b[39;49mdatamodule\n\u001b[1;32m    640\u001b[0m )\n\u001b[1;32m    642\u001b[0m \u001b[39m# TODO: ckpt_path only in v2.0\u001b[39;00m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n",
      "File \u001b[0;32m~/anaconda3/envs/css/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:139\u001b[0m, in \u001b[0;36mDataConnector.attach_data\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, test_dataloaders, predict_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m# Validate that the required data sources are available\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mFITTING:\n\u001b[0;32m--> 139\u001b[0m     _check_dataloader_none(train_dataloaders, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_dataloader_source, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mstate\u001b[39m.\u001b[39;49mfn)\n\u001b[1;32m    140\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mVALIDATING:\n\u001b[1;32m    141\u001b[0m     _check_dataloader_none(val_dataloaders, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_val_dataloader_source, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn)\n",
      "File \u001b[0;32m~/anaconda3/envs/css/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:598\u001b[0m, in \u001b[0;36m_check_dataloader_none\u001b[0;34m(dataloader, dataloader_source, trainer_fn)\u001b[0m\n\u001b[1;32m    596\u001b[0m prefix \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m trainer_fn \u001b[39m==\u001b[39m TrainerFn\u001b[39m.\u001b[39mFITTING \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m \u001b[39mif\u001b[39;00m dataloader \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m dataloader_source\u001b[39m.\u001b[39mis_defined():\n\u001b[0;32m--> 598\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    599\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn invalid dataloader was passed to `Trainer.\u001b[39m\u001b[39m{\u001b[39;00mtrainer_fn\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mprefix\u001b[39m}\u001b[39;00m\u001b[39mdataloaders=...)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    600\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Either pass the dataloader to the `.\u001b[39m\u001b[39m{\u001b[39;00mtrainer_fn\u001b[39m}\u001b[39;00m\u001b[39m()` method OR implement\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m `def \u001b[39m\u001b[39m{\u001b[39;00mdataloader_source\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m(self):` in your LightningModule/LightningDataModule.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    602\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: An invalid dataloader was passed to `Trainer.fit(train_dataloaders=...)`. Either pass the dataloader to the `.fit()` method OR implement `def train_dataloader(self):` in your LightningModule/LightningDataModule."
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = Trainer()\n",
    "trainer.fit(simclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "css",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
