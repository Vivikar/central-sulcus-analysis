{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC, SVR\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.metrics import roc_auc_score, r2_score, f1_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.data.splits import via11_splits\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_embdeds = pd.read_pickle('/mrhome/vladyslavz/git/central-sulcus-analysis/data/via11/nobackup/contrastive_embeddings/via11-monai-BasicUnet-2x-segmentDice+contrastive/sst_embeds.pkl')\n",
    "# sst_embdeds.encoder_embed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_paths = Path('/mnt/projects/VIA_Vlad/nobackup/MP2RAGE_FS7_1_1/mindboggle').glob('via*')\n",
    "metrics_paths = [x/'tables/left_cortical_surface/sulcus_shapes.csv' for x in metrics_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features2analyze = ['area', 'travel depth: median', 'geodesic depth: median', \n",
    "#                     'mean curvature: median',  'freesurfer curvature: MAD',\n",
    "#                     'freesurfer convexity (sulc): median', 'freesurfer thickness: median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features(subj_path):\n",
    "#     metrics_df = pd.read_csv(subj_path)\n",
    "#     metrics_df = metrics_df.set_index('name')\n",
    "#     features = dict(metrics_df.loc['central sulcus', :])\n",
    "#     features['caseid'] = 'sub-' + subj_path.parent.parent.parent.name\n",
    "#     return features\n",
    "# features_df = []\n",
    "# for subj_path in tqdm(metrics_paths):\n",
    "#     features_df.append(extract_features(subj_path))\n",
    "# features_df = pd.DataFrame(features_df).set_index('caseid')\n",
    "# features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "via_qc = pd.read_excel('/mnt/projects/VIA_Vlad/nobackup/QA_centralSulcus_lkj.xlsx')\n",
    "via_demo = pd.read_excel('/mnt/projects/VIA_Vlad/nobackup/VIA11_fmriflanker_info_database_2021jan25.xlsx')\n",
    "via_demo = via_demo[~via_demo.site.isna()]\n",
    "via_demo['caseid'] = ['sub-via'+str(i).zfill(3) for i in via_demo['via_id']]\n",
    "via_demo = via_demo.set_index('caseid')\n",
    "\n",
    "viaid2qc = {1:[], 2:[], 3:[], 999:[]}\n",
    "for i, row in via_qc.iterrows():\n",
    "    viaid2qc[row['vis_QA']].append(row['subjects'])\n",
    "    \n",
    "via_demo = via_demo.loc[np.concatenate(list(viaid2qc.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = via_demo[['group', 'sex', 'handedness', 'cbcl_total', 'cbcl_external', 'cbcl_internal', 'cgas', 'any_diagnosis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = sst_embdeds.merge(features_df, left_on='caseid', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    258\n",
       "1.0     26\n",
       "2.0     19\n",
       "Name: handedness, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.handedness.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_case_ids = np.random.choice(merged_df.caseid.unique(), 20, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_case_ids = np.random.choice(via11_splits['validation'], 20, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGR_feat = ['cbcl_total', 'cbcl_external',\n",
    "       'cbcl_internal', 'cgas']\n",
    "\n",
    "CATEG = ['group', 'sex', 'handedness', 'any_diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINGO\n",
      "For feature: cbcl_total\n",
      "R2 train: 0.28605082392060144\n",
      "R2 test: -0.30911648575534123\n",
      "\n",
      "MSE train: 241.82114261419912\n",
      "MSE test: 370.5923826739095\n",
      "____________________ \n",
      "\n",
      "BINGO\n",
      "For feature: cbcl_external\n",
      "R2 train: -0.023820727905786487\n",
      "R2 test: -0.3385424175618994\n",
      "\n",
      "MSE train: 24.002327779219844\n",
      "MSE test: 31.17580234587383\n",
      "____________________ \n",
      "\n",
      "BINGO\n",
      "For feature: cbcl_internal\n",
      "R2 train: 0.1359292965595037\n",
      "R2 test: -0.174084805591473\n",
      "\n",
      "MSE train: 36.69104309724179\n",
      "MSE test: 52.4402864414319\n",
      "____________________ \n",
      "\n",
      "BINGO\n",
      "For feature: cgas\n",
      "R2 train: 0.33525355784063293\n",
      "R2 test: -0.5299758707003428\n",
      "\n",
      "MSE train: 163.16811904228138\n",
      "MSE test: 324.1100884491607\n",
      "____________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "targ= 'mlp_embed'\n",
    "for f in REGR_feat:\n",
    "    clean_df = merged_df[~merged_df[f].isna()]\n",
    "    train_df = clean_df[~clean_df.caseid.isin(val_case_ids)]\n",
    "    test_df = clean_df[clean_df.caseid.isin(val_case_ids)]\n",
    "\n",
    "    train_y = train_df[f].values\n",
    "    train_X = np.vstack(train_df[targ].values)\n",
    "\n",
    "    test_y = test_df[f].values\n",
    "    test_X = np.vstack(test_df[targ].values)\n",
    "\n",
    "    lr = SVR()\n",
    "    train_pred_y = lr.fit(train_X, train_y).predict(train_X)\n",
    "    test_pred_y = lr.predict(test_X)\n",
    "\n",
    "    if r2_score(test_y, test_pred_y) > 0 or True:\n",
    "        print('BINGO')\n",
    "        print(f'For feature: {f}')\n",
    "        print(f'R2 train: {r2_score(train_y, train_pred_y)}')\n",
    "        print(f'R2 test: {r2_score(test_y, test_pred_y)}')\n",
    "        print()\n",
    "        print(f'MSE train: {np.mean((train_y - train_pred_y)**2)}')\n",
    "        print(f'MSE test: {np.mean((test_y - test_pred_y)**2)}')\n",
    "        print('____________________', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = clean_df.caseid.isin(via11_splits['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LabelBinarizer.fit_transform() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m test_pred_y \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mpredict(test_X)\n\u001b[1;32m     18\u001b[0m cat \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(train_y))\n\u001b[0;32m---> 19\u001b[0m train_y_ohe \u001b[39m=\u001b[39m LabelBinarizer()\u001b[39m.\u001b[39;49mfit_transform(train_y\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m),cat)\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m     20\u001b[0m test_y_ohe \u001b[39m=\u001b[39m LabelBinarizer()\u001b[39m.\u001b[39mfit_transform(test_y\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),cat)\u001b[39m.\u001b[39mtoarray()\n\u001b[1;32m     22\u001b[0m train_pred_y_proba \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39mfit(train_X, train_y)\u001b[39m.\u001b[39mpredict_proba(train_X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    148\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: LabelBinarizer.fit_transform() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "targ= 'mlp_embed'\n",
    "for f in CATEG:\n",
    "    clean_df = merged_df[~merged_df[f].isna()]\n",
    "    # train_df = clean_df[(~clean_df.caseid.isin(val_case_ids)) & val]\n",
    "    train_df = clean_df[(~clean_df.caseid.isin(val_case_ids))]\n",
    "    test_df = clean_df[clean_df.caseid.isin(val_case_ids)]\n",
    "\n",
    "    train_y = train_df[f].values\n",
    "    train_X = np.vstack(train_df[targ].values)\n",
    "\n",
    "    test_y = test_df[f].values\n",
    "    test_X = np.vstack(test_df[targ].values)\n",
    "\n",
    "    lr = SVC(probability=True, C=0.1)\n",
    "    train_pred_y = lr.fit(train_X, train_y).predict(train_X)\n",
    "    test_pred_y = lr.predict(test_X)\n",
    "    \n",
    "    cat = list(np.unique(train_y))\n",
    "    train_y_ohe = OneHotEncoder(categories=cat).fit_transform(train_y.reshape(-1, 1)).toarray()\n",
    "    test_y_ohe = OneHotEncoder(categories=cat).fit_transform(test_y.reshape(-1, 1)).toarray()\n",
    "    \n",
    "    train_pred_y_proba = lr.fit(train_X, train_y).predict_proba(train_X)\n",
    "    test_pred_y_proba = lr.predict_proba(test_X)\n",
    "    \n",
    "\n",
    "    if  True:\n",
    "        # print('BINGO')\n",
    "        print(f'For feature: {f}')\n",
    "        print(f'ROC-AUC train: {roc_auc_score(train_y_ohe, train_pred_y_proba, multi_class=\"ovr\")}')\n",
    "        print(f'ROC-AUC test: {roc_auc_score(test_y_ohe, test_pred_y_proba, multi_class=\"ovr\")}')\n",
    "        print()\n",
    "        print(f'F1 train: {f1_score(train_y, train_pred_y, average=\"macro\")}')\n",
    "        print(f'F1 test: {f1_score(test_y, test_pred_y, average=\"macro\")}')\n",
    "        print()\n",
    "        print(f'balanced_accuracy_score train: {balanced_accuracy_score(train_y, train_pred_y)}')\n",
    "        print(f'balanced_accuracy_score test: {balanced_accuracy_score(test_y, test_pred_y)}')\n",
    "        \n",
    "        print('____________________', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "css",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
